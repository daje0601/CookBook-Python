{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**목차**   \n",
    "  \n",
    "1. About Dataset  \n",
    "  * 데이터 선택 사유   \n",
    "  * 타겟 선정 및 선택 사유   \n",
    "  * 데이터 로드 및 확인  \n",
    "  * feature 설명  \n",
    "    \n",
    "2. EDA\n",
    "  * EDA \n",
    "   -. 특수문자 -> 영어로 변환하기  \n",
    "   -. title 정보로 region1 결측치 채우기  \n",
    "   -. title에서 연도 분리하기   \n",
    "  * Feature Engineering \n",
    "   -. description 분석   \n",
    "   -. country기준으로 designation Features수 줄이기   \n",
    "  * 데이터 정규화   \n",
    "   -. 각 feature 정규화 \n",
    "  * 노이즈 제거\n",
    "   -. price feature 이상치 줄이기   \n",
    "  * 데이터 밸런스(외도, 척도) 확인 \n",
    "  * Data leakage 확인\n",
    "  * 유용성 여부 및 한계 피드백 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. About Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1) 데이터 선정사유 \n",
    "  \n",
    "\n",
    "최근 체결한 RCEP협정은 대한민국이 성공적이다는 평가를 받는다. 이는 대한민국 기업에 상당한 이익과 성장시간을 보장해준 협정이라 평가받는다.  \n",
    "이러한 시대적 분위기에 편승하여 이번에는 유럽과 미국도 제 2의 RCEP를 체결하고자 대한국민 기재부는 노력중에 있다.  \n",
    "그중 일환으로 와인에 대한 균일평등화 작업이 진행되고 있으며, 와인의 대중화를 높이고자 다각적인 측면에서 검토가 진행중에 있다.  \n",
    "\n",
    "와인 담당자는 DS.ltd에 지난 10년간 10만건 이상의 데이터 분석을 통해 와인의 가격에 대한 머신러닝 모델 제작을 요청하였다. \n",
    "\n",
    "1. 선정사유(1) : DS.ltd에서는 캐글에 업로드된 wine 데이터 중 10만건 이상되는 데이터로 분석을 진행하고자 한다. \n",
    "2. 선정사유(2) : 화학성분이 기재된 wine 데이터도 있었으나, 대중화를 목적으로 둔 본 분석과 이질감이 있다 사료하여 해당 데이터로 선정하였다. \n",
    "\n",
    "\n",
    "\n",
    "위와 같은 사유로 DS.ltd에서는 해당 데이터로 와인 가격분석을 진행하고자 합니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2) target 선정사유 \n",
    "\n",
    "  \n",
    "우리는 기존에 판매된 와인가격에 대한 분석을 진행해야 하므로 price를 target으로 선정토록 하겠습니다.  \n",
    "  \n",
    "또한, price를 기준으로 어떤 와인이 좋다 나쁘다의 분류를 하는 것이 아니며   \n",
    "적절한 가격은 얼마정도인지 가격 예측을 목표로 하기 때문에 회귀분석으로 접근토록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3) 데이터 로드 및 확인  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\user\\Documents\\pandas_study\\bootcamp_DS\\project\\section2_porject_210222\\winemag-data-130k-v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description   designation  \\\n",
       "0     Italy  Aromas include tropical fruit, broom, brimston...  Vulkà Bianco   \n",
       "1  Portugal  This is ripe and fruity, a wine that is smooth...      Avidagos   \n",
       "\n",
       "   points  price           province region_1 region_2    taster_name  \\\n",
       "0      87    NaN  Sicily & Sardinia     Etna      NaN  Kerin O’Keefe   \n",
       "1      87   15.0              Douro      NaN      NaN     Roger Voss   \n",
       "\n",
       "  taster_twitter_handle                                          title  \\\n",
       "0          @kerinokeefe              Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger  Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129971, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터량 확인\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                     63\n",
       "description                  0\n",
       "designation              37465\n",
       "points                       0\n",
       "price                     8996\n",
       "province                    63\n",
       "region_1                 21247\n",
       "region_2                 79460\n",
       "taster_name              26244\n",
       "taster_twitter_handle    31213\n",
       "title                        0\n",
       "variety                      1\n",
       "winery                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 결측치 확인 \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129971 entries, 0 to 129970\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   country                129908 non-null  object \n",
      " 1   description            129971 non-null  object \n",
      " 2   designation            92506 non-null   object \n",
      " 3   points                 129971 non-null  int64  \n",
      " 4   price                  120975 non-null  float64\n",
      " 5   province               129908 non-null  object \n",
      " 6   region_1               108724 non-null  object \n",
      " 7   region_2               50511 non-null   object \n",
      " 8   taster_name            103727 non-null  object \n",
      " 9   taster_twitter_handle  98758 non-null   object \n",
      " 10  title                  129971 non-null  object \n",
      " 11  variety                129970 non-null  object \n",
      " 12  winery                 129971 non-null  object \n",
      "dtypes: float64(1), int64(1), object(11)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# df1.info로 확인 결과 대부분 object 데이터 타입임을 확인하였다. \n",
    "# check the data info -> This data is almost object types \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <td>98758</td>\n",
       "      <td>15</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>25514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_2</th>\n",
       "      <td>50511</td>\n",
       "      <td>17</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>11065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taster_name</th>\n",
       "      <td>103727</td>\n",
       "      <td>19</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>25514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>129908</td>\n",
       "      <td>43</td>\n",
       "      <td>US</td>\n",
       "      <td>54504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>province</th>\n",
       "      <td>129908</td>\n",
       "      <td>425</td>\n",
       "      <td>California</td>\n",
       "      <td>36247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <td>129970</td>\n",
       "      <td>707</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>13272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_1</th>\n",
       "      <td>108724</td>\n",
       "      <td>1229</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winery</th>\n",
       "      <td>129971</td>\n",
       "      <td>16757</td>\n",
       "      <td>Wines &amp; Winemakers</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>designation</th>\n",
       "      <td>92506</td>\n",
       "      <td>37979</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>129971</td>\n",
       "      <td>118840</td>\n",
       "      <td>Gloria Ferrer NV Sonoma Brut Sparkling (Sonoma...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>129971</td>\n",
       "      <td>119955</td>\n",
       "      <td>Ripe plum, game, truffle, leather and menthol ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count  unique  \\\n",
       "taster_twitter_handle   98758      15   \n",
       "region_2                50511      17   \n",
       "taster_name            103727      19   \n",
       "country                129908      43   \n",
       "province               129908     425   \n",
       "variety                129970     707   \n",
       "region_1               108724    1229   \n",
       "winery                 129971   16757   \n",
       "designation             92506   37979   \n",
       "title                  129971  118840   \n",
       "description            129971  119955   \n",
       "\n",
       "                                                                     top  \\\n",
       "taster_twitter_handle                                         @vossroger   \n",
       "region_2                                                   Central Coast   \n",
       "taster_name                                                   Roger Voss   \n",
       "country                                                               US   \n",
       "province                                                      California   \n",
       "variety                                                       Pinot Noir   \n",
       "region_1                                                     Napa Valley   \n",
       "winery                                                Wines & Winemakers   \n",
       "designation                                                      Reserve   \n",
       "title                  Gloria Ferrer NV Sonoma Brut Sparkling (Sonoma...   \n",
       "description            Ripe plum, game, truffle, leather and menthol ...   \n",
       "\n",
       "                        freq  \n",
       "taster_twitter_handle  25514  \n",
       "region_2               11065  \n",
       "taster_name            25514  \n",
       "country                54504  \n",
       "province               36247  \n",
       "variety                13272  \n",
       "region_1                4480  \n",
       "winery                   222  \n",
       "designation             2009  \n",
       "title                     11  \n",
       "description                3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# object data의 unique를 살펴보았다. \n",
    "df.describe(exclude='number').T.sort_values(by='unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4) feature 설명 \n",
    "  \n",
    "'country' - 어느나라에서 생산되었는지  \n",
    "'description' - 와인 시음 후 와인에 대한 평가 및 설명   \n",
    "'designation' - 양조장이 있는 포도원   \n",
    "'points' - 시음 후 와인 점수   \n",
    "'price' - 와인의 가격 ( \"our target\" )  \n",
    "'province' - 와인 제작 시, 사용되는 포도의 출처   \n",
    "'region_1' - 포도가 자라는 지역 \n",
    "'region_2' - 포도가 자라는 지역을 상세하게 기재한 feature\n",
    "'taster_name' - 시음한 사람     \n",
    "'taster_twitter_handle' 시음한 사람의 트위터   \n",
    "'title' - 와인명  \n",
    "'variety' - 와인을 만들때 혼합된 포도  \n",
    "'winery' - 양조장명  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **☆ 지금까지 insight ☆**  \n",
    " 1. designation과 winery를 동일하게 양조장에 대한 정보를 나타내고 있다.  \n",
    "     -> 확인 후 합칠 수 있는 것들은 혼합할 예정   \n",
    "       \n",
    " 2. region_1과 region_2도 동일한 정보를 나타내며, title에 region정보가 있는 것을 확인할 수 있었다.  \n",
    "    -> 결측치는 이로 대체 예정 \n",
    "      \n",
    " 3. taster_name와 taster_twitter_handle도 taster에 대한 동일한 정보를 제공해주고 있다.  \n",
    "    -> 확인 후 합칠 수 있는 것들은 혼합할 예정 \n",
    "      \n",
    " 4. title, variety, winery 등은 결측치가 거의 없다. 이에, 해당 데이터를 활용하여 결측치를 채울 수 있는 것들은 채울 예정\n",
    "   \n",
    " 5. description을 split하여 aroma, blend, sweet 등의 단어를 찾아서 타겟과의 연관관계를 확인해보고자 한다    \n",
    "   \n",
    " 6. 또한, 너무 unique가 높기 때문에 각 feature별로 count하여 count된 만큼 페센트로 가중치를 주고자 한다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ☆ 나라별 용어 따른 숙성 정도 차이 ☆\n",
    "\n",
    "7. 스페인, 이탈리아 ( 법적 필수 준수사항 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " |등급|내용|\n",
    " |----|-----|\n",
    " |joven|전혀 숙성을 시키지 않고 바로 출시된 와인|\n",
    " |crianza|최소 24개월이상 오크 및 병에 담아 숙성 후 출시된 와인|\n",
    " |reserva|최소 36개월이상 오크 및 병에 담아 숙성 후 출시된 와인|\n",
    " |gran reserva|최소 60개월이상 오크 및 병에 담아 숙성 후 출시된 와인|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 그외나라(미국, 칠레, 호주, 뉴질랜드 등)   \n",
    " -. 별다른 규정 없이 바로 taster에게 좋은 평가를 받으면 reserva라는 표기 가능   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 기타(혼용되는 용어)  \n",
    " -. reserva는 나라에 따라서 riserva, reserve 등으로 혼용되어 사용된다고 한다.  \n",
    " -. [\"À\", \"A\"],[\"Á\", \"A\"],[\"Â\", \"A\"],[\"Ã\", \"A\"],[\"Ä\", \"A\"],[\"Ä\", \"A\"],[\"Å\", \"A\"]  \n",
    " -. ,[\"à\", \"a\"],[\"á\", \"a\"],[\"â\", \"a\"],[\"ã\", \"a\"],[\"ä\", \"a\"],[\"ä\", \"a\"],[\"å\", \"a\"]  \n",
    " -. ,[\"È\", \"E\"],[\"É\", \"E\"],[\"Ê\", \"E\"],[\"Ë\", \"E\"],[\"Ë\", \"E\"]  \n",
    " -. ,[\"è\", \"e\"],[\"é\", \"e\"],[\"ê\", \"e\"],[\"ë\", \"e\"],[\"ë\", \"e\"]  \n",
    " -. ,[\"Æ\", \"AE\"],[\"æ\", \"ae\"],[\"Ç\", \"C\"],[\"ç\", \"c\"]  \n",
    " -. ,[\"Ì\", \"I\"],[\"Í\", \"I\"],[\"Î\", \"I\"],[\"Ï\", \"I\"],[\"Ï\", \"I\"]  \n",
    " -. ,[\"ì\", \"i\"],[\"í\", \"i\"],[\"î\", \"i\"],[\"ï\", \"i\"],[\"ï\", \"i\"]  \n",
    " -. ,[\"Ð\", \"D\"],[\"ð\", \"d\"],[\"Ñ\", \"N\"],[\"ñ\", \"n\"]  \n",
    " -. ,[\"Ò\", \"O\"],[\"Ó\", \"O\"],[\"Ô\", \"O\"],[\"Õ\", \"O\"],[\"Ö\", \"O\"],[\"Ö\", \"O\"],[\"Œ\", \"OE\"]   \n",
    " -. ,[\"ò\", \"o\"],[\"ó\", \"o\"],[\"ô\", \"o\"],[\"õ\", \"o\"],[\"ö\", \"o\"],[\"ö\", \"o\"],[\"œ\", \"oe\"]  \n",
    " -. ,[\"Ù\", \"U\"],[\"Ú\", \"U\"],[\"Û\", \"U\"],[\"Ü\", \"U\"],[\"Ü\", \"U\"]  \n",
    " -. ,[\"ù\", \"u\"],[\"ú\", \"u\"],[\"û\", \"u\"],[\"ü\", \"u\"],[\"ü\", \"u\"]  \n",
    " -. ,[\"Ý\", \"Y\"],[\"Ÿ\", \"Y\"],[\"Ÿ\", \"Y\"]  \n",
    " -. ,[\"ý\", \"y\"],[\"ÿ\", \"y\"],[\"ÿ\", \"y\"]  \n",
    " -. ,[\"Þ\", \"P\"],[\"þ\", \"p\"],[\"ß\", \"s\"][\"¡\", \"!\"][\"¿\", \"?\"]  \n",
    "  -> 위 용어를 모두 분석한 결과, 부분적으로만 대문자로 시작되는 글자는 없었으며,    \n",
    "  -> 제품의 발음을 위해 France 등 일부 유럽국가에서만 특수문자로 기재가 되어 있음을 확인하였다.   \n",
    "  -> 이에, 카테고리티를 줄이기 위해서 이를 통일하는 작업이 필요하다가 생각된다. \n",
    "\n",
    "10. 출처   \n",
    " -. 와인등급 :https://www.wine21.com/11_news/news_view.html?Idx=17111  \n",
    " -. 와인등급 : https://m.blog.naver.com/interkj87/220699483883  \n",
    " -. 와인등급 : https://www.decantalo.com/en/blog/winemaking/classifying-wines-by-their-age-crianza-reserva-gran-reserva/  \n",
    " -. 유럽(문자) 표기법:http://help.hancom.com/hoffice/multi/ko_kr/hwp/insert/europe.htm\n",
    "※ 모든 title에 해당 정보가 기재되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유럽(외국문자) 표기법\n",
    "http://help.hancom.com/hoffice/multi/ko_kr/hwp/insert/europe.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA\n",
    "\n",
    "\n",
    "   -. \n",
    "   -.   \n",
    "  * Feature Engineering \n",
    "   -. description 분석   \n",
    "   -. country기준으로 designation Features수 줄이기   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 혼용되는 용어 통일을 위한 object 추출 \n",
    "df.select_dtypes(exclude=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혼용되는 용어 통일을 위한 object 리스트화\n",
    "object_columns = ['country', 'description', 'designation', 'province', 'region_1',\n",
    "       'region_2', 'taster_name', 'taster_twitter_handle', 'title', 'variety',\n",
    "       'winery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[object_columns].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[~df.isnull()][\"variety\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 위에서도 언급한 바와 같이 같은 용어인데 나라별로 철자를 다르게 사용한다. \n",
    "# 이에, 용어를 통일하고자 한다. \n",
    "\n",
    "for column in df[~df.isnull()][object_columns]:\n",
    "    df[column] = df[column].str.replace(\"reserva\",\"reserve\")\n",
    "    df[column] = df[column].str.replace(\"riserva\",\"reserve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"designation\",\"description\" -> 변경된 값이 모두 정상적으로 변경되어 출력되지 않음\n",
    "df[[\"designation\",\"description\"]].query('description.str.contains(\"reserva\")',engine='python').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1) 특수문자 -> 영어로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 문자 영어로 통일 \n",
    "# 위에서도 언급한 바와 같이 해당 데이터에는 발음의 구분 목적으로 \n",
    "# 특수문자가 기재되어 있어 해당 데이터를 영어로 변환해주고자 함 \n",
    "\n",
    "lists = [[\"À\",\"Á\",\"Â\",\"Ã\",\"Ä\",\"Ä\",\"Å\"]\n",
    "        ,[\"à\",\"á\",\"â\",\"ã\",\"ä\",\"ä\",\"å\"]\n",
    "        ,[\"È\",\"É\",\"Ê\",\"Ë\",\"Ë\"]\n",
    "        ,[\"è\", \"é\", \"ê\", \"ë\", \"ë\"]     \n",
    "        ,[\"ç\", \"c\"]\n",
    "        ,[\"ì\",\"í\",\"î\",\"ï\",\"ï\"]\n",
    "        ,[\"ò\",\"ó\",\"ô\",\"õ\",\"ö\",\"ö\",\"œ\"]\n",
    "        ,[\"ñ\"]\n",
    "        ,[\"ù\",\"ú\",\"û\",\"ü\",\"ü\"]\n",
    "        ,[\"ý\",\"ÿ\",\"ÿ\"]]\n",
    "\n",
    "for list in lists[0][1] :\n",
    "    df = df.replace(list, \"a\", regex=True)\n",
    "\n",
    "for list in lists[2][3] :\n",
    "    df = df.replace(list, \"e\", regex=True)\n",
    "    \n",
    "for list in lists[4] :\n",
    "    df = df.replace(list, \"c\", regex=True)\n",
    "    \n",
    "for list in lists[5] :\n",
    "    df = df.replace(list, \"i\", regex=True)\n",
    "    \n",
    "for list in lists[6] :\n",
    "    df = df.replace(list, \"o\", regex=True)\n",
    "    \n",
    "for list in lists[7] :\n",
    "     df = df.replace(list, \"n\", regex=True)\n",
    "    \n",
    "for list in lists[8] :\n",
    "    df = df.replace(list, \"u\", regex=True)\n",
    "    \n",
    "for list in lists[9] :\n",
    "    df = df.replace(list, \"y\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 대문자 -> 소문자\n",
    "for column in object_columns:\n",
    "    df[column] = df[column].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모두 제거 되고, 대문자로 소문자로 변경된 것을 확인 \n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2) title를 통해 region 결측치 해결하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"region_1\",\"title\" 관찰 \n",
    "df[[\"region_1\",\"title\"]].query('title.str.contains(\"joven\")',engine='python').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 데이터를 살펴본 결과, title의 괄호 부분이 region_1를 나타냄을 알 수 있었다.\n",
    "이로 region_1의 결측치 21,247개를 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 먼저 (로 split하고 1번째 인덱스를 region으로 저장 \n",
    "df['region'] = df.title.str.split('(').str[1]\n",
    "\n",
    "# 먼저 )로 split하고 1번째 인덱스를 region으로 저장 \n",
    "df['region'] = df.region.str.split(')').str[0]\n",
    "df['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데어터 컬럼 생성여부 확인\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"title\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['region_1'].isnull().sum())\n",
    "print(df['region'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "region_1보다는 결측치를 만개주렸다. title에는 결측치가 없으나, title내에 ()로 지역명이 기재되어 있지 않은 데이터가 1만개 정도 있는 것 같다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_count = pd.DataFrame(df[\"region\"].value_counts())\n",
    "region_count[\"region\"] = region_count[\"region\"]/len(region_count[\"region\"])\n",
    "region_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, region_count, left_on=\"region\", right_index=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3) title에서 연도 분리하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"region_1\",\"title\" 관찰 \n",
    "df[[\"title\"]].query('title.str.contains(\"joven\")',engine='python').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title에는 와인 규정상 생성된 연도를 기재하게 되어 있다.  \n",
    "이 특성을 이용하여 와인의 생성연도를 구해보고자 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwe(row):\n",
    "    return re.findall(\"\\d+\", row)\n",
    "\n",
    "df['year'] = df['title'].apply(qwe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # year feature 생성 \n",
    "# title_lists = df[\"title\"].tolist()\n",
    "# for list in title_lists :\n",
    "#     test = re.findall(\"\\d+\", list)\n",
    "\n",
    "#     for i in test:\n",
    "#         n = 0 \n",
    "#         if int(i) > 1990 :\n",
    "#             df[\"year\"][n, :] = int(i)\n",
    "#         else :\n",
    "#             df[\"year\"][n, :] = 0\n",
    "#         n = n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4) winery에 가중치 부여하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"winery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"winery\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"winery\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 데이터를 살펴보니 unique는 높으나 결측치가 없는 것을 확인된다.  \n",
    "이에 해당 데이터를 카테고리별로 카운트하여 총 카운트된 갯수로 나누어준 점수로 구성된  \n",
    "새로운 feature를 만들어주고자 한다.\n",
    "\n",
    "위와 같이 처리를 하였을 때 좋은 점은 개별점수가 하나의 개별 unique가 되면서 회귀분석을 진행할 수 있다는 점이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winery value_count 및 score 생성 \n",
    "winery_count = pd.DataFrame(df[\"winery\"].value_counts())\n",
    "winery_count[\"winery\"] = winery_count[\"winery\"]/len(winery_count[\"winery\"])\n",
    "winery_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling을 통한 카테고리데이터 점수화 및 merge\n",
    "df = pd.merge(df, winery_count, left_on=\"winery\", right_index=True)\n",
    "df.head(1)\n",
    "\n",
    "# 카피가 되면서 merge가 되어 추후 필요없는 feature는 일괄적으로 삭제 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"winery_y\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5) winery에 가중치 부여하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['variety'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "카테고리티가 너무 높기 때문에 이를 이대로 인코더를 통해 학습을 진행할 경우 문제가 feature가 너무나 많아지게 된다. 이에, 해결하기 위해 아래와 같이 2가지를 고민하였다.\n",
    "\n",
    "구간별로 그룹을 지어 카테고리별로 분리를 할 것인지\n",
    "count / len로 각 카테고리별 점수표를 만들어서 가중치를 줄것인지\n",
    "1번을 선택할 경우, 그룹을 나누는 기준을 선정하는 것이 매우 모호하다\n",
    "수량으로 기준을 나누자니 아래 variety_point에서 관찰되듯 variety_count가 높다고 무조건 max score가 높은 것도 아니며, 평균이 높은 것도 아니다. 이에, 2번 방법으로 각 카테코리별 점수표를 만들어 가중치를 주고자 한다.\n",
    "\n",
    "위와 같이 처리를 하였을 때 좋은 점은 개별점수가 하나의 개별 unique가 되면서 회귀분석을 진행할 수 있다는 점이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variety_point = df.groupby(['variety']).points.agg([len, min, max, sum])\n",
    "variety_point[\"mean\"] = variety_point[\"sum\"]/variety_point[\"len\"]\n",
    "variety_point.sort_values(by=\"len\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variety_count = pd.DataFrame(df[\"variety\"].value_counts())\n",
    "variety_count[\"variety\"] = variety_count[\"variety\"]/len(variety_count[\"variety\"])\n",
    "variety_count.shape # 누락된 값있는지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 생성된 variety_count vs variety unique 비교 \n",
    "df[\"variety\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# variety를 카운트하여 해당 카테고리를 인트로 변환하여 주었다. \n",
    "# 추후 scaler를 통하여 해당 값들은 조정해줄 예정이다. \n",
    "df = pd.merge(df, variety_count, left_on=\"variety\", right_index=True)\n",
    "df.head(2)\n",
    "\n",
    "# 카피가 되면서 merge가 되어 추후 필요없는 feature는 일괄적으로 삭제 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-6) description 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description을 구성하는 단어 살펴보기 \n",
    "df[\"description\"] = df[\"description\"].str.split(\" \")\n",
    "lists = df[\"description\"].tolist()\n",
    "\n",
    "all_list = []\n",
    "for list in lists:\n",
    "    for item in list:\n",
    "        all_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어가 각각 총 몇번 언급되었는지 확인 \n",
    "counts = {}\n",
    "for list in all_list :\n",
    "    counts[list] = counts.get(list, 0) + 1\n",
    "    \n",
    "{k: v for k, v in sorted(counts.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 description을 분석한 결과, 검색되는 데이터량이 너무 많고 이들 중 wine을 대표할만한 키워드를 찾는다하여도 feature수가 급증하며, 문장으로써 의미를 갖는 것에 대한 가중치를 계산하는 것이 불가능하므로 해당 feature는 분석에서 제외토록 하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-7) designation 확인하기 - feature groupby 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 최초 unique(37979)에서 특수문자 & 용어통일작업으로  unique(37609)로 감소 ( 감소량 : 370)\n",
    "df[\"designation\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 언급한 등급으로 해당 feature를 그룹화해보고자 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 문자를 replace하는데 조금 더 효율적으로 변환하기 위해 공백을 _로 변경\n",
    "# df[\"designation\"] = df[\"designation\"].str.replace(\" \", \"_\")\n",
    "\n",
    "# # 결측치가 있는 경우, replace 오류가 발생됨 \n",
    "# # 이에, ~ 를 통해 결측치 있는 부분은 제외하고 designation을 선택하여 \n",
    "# # 등급별로 변환하는 작업을 진행함 \n",
    "# for grade in df.loc[~df[\"designation\"].isnull()][\"designation\"]:\n",
    "#     if \"joven\" in grade:\n",
    "#         df[\"designation\"] = df[\"designation\"].str.replace(grade, \"joven\")\n",
    "#     if \"crianza\" in grade:\n",
    "#         df[\"designation\"] = df[\"designation\"].str.replace(grade, \"crianza\")\n",
    "#     if \"gran_reserve\" in grade:\n",
    "#         df[\"designation\"] = df[\"designation\"].str.replace(grade, \"gran_reservA\")\n",
    "#     if \"reserve\" in grade:\n",
    "#         df[\"designation\"] = df[\"designation\"].str.replace(grade, \"reserve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 처리를 하는 것은 매우 시간이 오래걸리고, unique가 1만개정도 밖에 감소를 하지 않기에 해당방법은 사용하지 않도록 하겠습니다. 담당자가 생각한 것과는 다르게 designation를 모두 그룹화 되지 못하였습니다. \n",
    "이에, 각 카테고리별 가중치를 부여하여 해당 문제를 해결하고 합니다. ( 시간이 오래걸려 해당 CODE는 주석처리함 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation_count = pd.DataFrame(df[\"designation\"].value_counts())\n",
    "designation_count[\"designation\"] = designation_count[\"designation\"]/len(designation_count[\"designation\"])\n",
    "designation_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, designation_count, left_on=\"designation\", right_index=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "province_count = pd.DataFrame(df[\"province\"].value_counts())\n",
    "province_count[\"province\"] = province_count[\"province\"]/len(province_count[\"province\"])\n",
    "province_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, province_count, left_on=\"province\", right_index=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_count = pd.DataFrame(df[\"country\"].value_counts())\n",
    "country_count[\"country\"] = country_count[\"country\"]/len(country_count[\"country\"])\n",
    "country_count.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, country_count, left_on=\"country\", right_index=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['points'].value_counts().sort_index().plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['winery_y'].value_counts().sort_index().plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"pastel\")\n",
    "sns.jointplot(x='variety_y', y='points', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='winery_y', y='points', data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(y='winery_y', x='variety_y', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 숫자형데이터를 시각화 및 분석하였을 때 해당 feature간의 명확하게 관찰되는 상관관계는 없었다. 모델을 돌리면서 상호간의 인과관계가 있는지 체크해볼 필요가 있을듯 하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 상관관계수 체크!\n",
    "df.select_dtypes(['int64','float64']).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df.query('price < 200').price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1) LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 필요없는 feature 제거 \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['points', 'price','winery_y', 'variety_y', 'designation_y', 'province_y',\n",
    "       'region_y', 'country_y']\n",
    "\n",
    "target = 'price'\n",
    "df1 = df[feature_list]\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df1, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_test = test.drop(columns=target)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터정규화**  \n",
    "각각의 모델에 동일하게 적용하기 위해서 인코딩 작업을 별도로 진행함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_encoded = encoder.fit_transform(X_train) # 학습데이터\n",
    "X_train_encoded = scaler.fit_transform(X_train_encoded)\n",
    "X_val_encoded = encoder.transform(X_val) # 검증데이터\n",
    "X_val_encoded = scaler.fit_transform(X_val_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* StandardScaler pipe1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(\n",
    "    StandardScaler(with_mean=False),\n",
    "    SimpleImputer(), \n",
    "    LinearRegression()\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1.fit(X_train_encoded, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MaxAbsScaler pipe2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(\n",
    "\n",
    "    MaxAbsScaler(),\n",
    "    SimpleImputer(), \n",
    "    LinearRegression()\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe2.fit(X_train_encoded, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"훈련 데이터 pipe1 score: {pipe1.score(X_train_encoded, y_train)}\")\n",
    "print(f\"검증 데이터 pipe1 score: {pipe1.score(X_val_encoded, y_val)}\")\n",
    "\n",
    "print(\"---\")\n",
    "\n",
    "print(f\"훈련 데이터 pipe2 score: {pipe2.score(X_train_encoded, y_train)}\")\n",
    "print(f\"검증 데이터 pipe2 score: {pipe2.score(X_val_encoded, y_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위 스코어를 베이스라인 및 베이스모델로 사용\n",
    "  -. 본 분석은 회귀 분석으로 가장 단순한 선형모델의 점수를 베이스라인을 정하는 것이 타당하다 사료됨 ( 그 외 고성능을 가진 모델을 베이스라인을 잡는 것은 좋은 모델이 가져다주는 이점이 스코어에 반영되기 때문에 기준으로 잡는 것은 무리가 있음 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1-1) 이상치 제거(밸런스 조정) \n",
    " -. 데이터가 너무 좋지 않게 나와서 이상치를 일괄적으로 제거하고자 함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_based_outlier(df):\n",
    "    for i in range(0, len(df.iloc[1])):\n",
    "        df.iloc[:,i] = df.iloc[:,i].replace(0, np.NaN)\n",
    "        df = df[~(np.abs(df.iloc[:,i] - df.iloc[:,i].mean()) > (3*df.iloc[:,i].std()))].fillna(0)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = std_based_outlier(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2) RandomForest & gridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param = { \n",
    "    #50 ~ 100으로 실행했을 때 최적이 100옴\n",
    "    # 범위 변경 : (50~100) -> (50~500)\n",
    "    'n_estimators': randint(50, 500), \n",
    "    # 과적합을 방지하기 위해 max를 20으로 설정함 \n",
    "    'max_depth': [5, 10, 15, 20, None], \n",
    "    # 최대 선택할 특성 수\n",
    "    'max_features': uniform(0, 1), \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42), \n",
    "    param_distributions=param, \n",
    "    n_iter=5, # 데이터의 훈련횟수\n",
    "    cv=3, # 교차검증 횟수\n",
    "    # mae은 에러 측정용으로써 낮을 수록 좋은데\n",
    "    # sklearn은 값이 클수록 좋다고 평가를 하기에 neg를 붙혀서 scoring으로 사용 \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, # 실행 과정 출력 여부\n",
    "    return_train_score=True, \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('최적 하이퍼파라미터: ', search.best_params_)\n",
    "print('CV MAE: ', -search.best_score_)\n",
    "model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"최적 모델 훈련 스코어 : {model.score(X_train, y_train)}\")\n",
    "print(f\"최적 모델 테스트 스코어 : {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**이상치 제거전 검증결과들**  \n",
    "1회차  \n",
    "param_distributions = { \n",
    "    'bootstrap': [True],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], \n",
    "    'max_depth': [10, 15, 20, None], \n",
    "    'max_features': ['auto', 'sqrt'], \n",
    "    'min_samples_leaf': [2, 4, 6],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=8282), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=5, \n",
    "    cv=3, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1, \n",
    "    random_state=8282\n",
    ")  \n",
    "0.5923866823401831  \n",
    "0.4410572771628445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2회차   \n",
    "param_distributions = { \n",
    "    'bootstrap': [True],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], \n",
    "    'max_depth': [5, 10, 15, None], \n",
    "    'max_features': ['auto', 'sqrt'], \n",
    "    'min_samples_leaf': [4, 8, 12],\n",
    "    'min_samples_split': [4, 8, 12]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=8282), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=100, \n",
    "    cv=3, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, \n",
    "    return_train_score=True, \n",
    "    n_jobs=-1, \n",
    "    random_state=8282\n",
    ")    \n",
    "0.5621359490859237    \n",
    "0.42881779691323074    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3) XGboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "boosting = XGBRegressor(\n",
    "    n_estimators=5000,\n",
    "    objective='reg:squarederror', # default\n",
    "    learning_rate=0.01,\n",
    "    max_depth=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "eval_set = [(X_train_encoded, y_train), \n",
    "            (X_val_encoded, y_val)]\n",
    "\n",
    "boosting.fit(X_train_encoded, y_train, \n",
    "          eval_set=eval_set,\n",
    "          early_stopping_rounds=1000\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = boosting.predict(X_val_encoded)\n",
    "print('R^2:', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4) XGboost hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'objective':['reg:linear'],\n",
    "              'learning_rate': [.01, .03, .05, .07], #GBM 내려가는 정도 \n",
    "              'max_depth': [9, 10, 11], # tree 깊이 ( 과적합 방지용 )\n",
    "              'min_child_weight': [1],# child의 잎 갯수 과적합 방지용\n",
    "              'subsample': [0.7], # 훈련 인스턴스의 서브 샘플 비율 (과적 합 방지)\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5000]}\n",
    "\n",
    "xgb_grid = GridSearchCV(XGBRegressor(),\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "eval_set = [(X_train_encoded, y_train), \n",
    "            (X_val_encoded, y_val)]\n",
    "\n",
    "xgb_grid.fit(X_train_encoded, y_train, \n",
    "          eval_set=eval_set,\n",
    "          early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\n",
    "model = xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear, RandomForest, Xgboost를 사용하여 모델을 학습한 결과 아래와 같은 결과값을 리턴받았다.\n",
    "RandomForest(0.518) > Xgboost(0.473) > linear(0.34) \n",
    "  \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **베이스라인과 비교하여 결과값에 대해 피드백**\n",
    "워낙 베이스 라인이 낮게 나왔고 학습이 잘 이루어진 것으로 보기는 어려움이 있다.  \n",
    "그러나, 데이터가 워낙 비선형적인 관계이며 데이터들 간의 인관관계가 없기에 학습이 적절히 이루어지지 않는 것으로 사료된다. 이에, RandomForest의 스코어가 가장 높은 것으로 사료된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개선을 위한 벙법과 그 방법을 선택한 사유 \n",
    "\n",
    "1. 개선하기 위해 일단 모든 데이터의 이상치를 제거해주는 작업을 진행하였다.   \n",
    "  -. 특이치에 대해 모델이 민감하게 반응하는 것으로 사료하여 제거  \n",
    "  -. 제거 후 성능이 향상됨 ( 그러나, 신뢰할 만한 모델은 만들지 못함 )   \n",
    "\n",
    "2. 과적합이 될 수 있도록 하이퍼파라미터 조절   \n",
    "  -. 워낙 학습이 이루어지지 않다보니 일부러 과적합을 시켜서 학습이 진행될 수 있도록 푸시함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내가 만든 모델의 유용성 및 한계\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 시각화 및 분석설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.displot(y_train, kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row = X_test.iloc[[2]] \n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(row)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value, \n",
    "    shap_values=shap_values,\n",
    "    features=row\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = X_test.iloc[[100]] \n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(row)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value, \n",
    "    shap_values=shap_values,\n",
    "    features=row\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_count[\"region\"].values[0.0006725]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_count[\"region\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_count[region_count[\"region\"] == 0.0006725 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test.iloc[:100])\n",
    "shap.force_plot(explainer.expected_value, shap_values, X_test.iloc[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
