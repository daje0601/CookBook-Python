{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\user\\Documents\\pandas_study\\bootcamp_DS\\project\\section2_porject_210222\\winemag-data-130k-v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = ['country', 'description', 'designation', 'province', 'region_1',\n",
    "       'region_2', 'taster_name', 'taster_twitter_handle', 'title', 'variety',\n",
    "       'winery']\n",
    "\n",
    "for column in df[~df.isnull()][object_columns]:\n",
    "    df[column] = df[column].str.replace(\"reserva\",\"reserve\")\n",
    "    df[column] = df[column].str.replace(\"riserva\",\"reserve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in object_columns:\n",
    "    df[column] = df[column].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 (로 split하고 1번째 인덱스를 region으로 저장 \n",
    "df['region'] = df.title.str.split('(').str[1]\n",
    "\n",
    "# 먼저 )로 split하고 1번째 인덱스를 region으로 저장 \n",
    "df['region'] = df.region.str.split(')').str[0]\n",
    "\n",
    "region_count = pd.DataFrame(df[\"region\"].value_counts())\n",
    "region_count[\"region\"] = region_count[\"region\"]/len(region_count[\"region\"])\n",
    "df = pd.merge(df, region_count, left_on=\"region\", right_index=True)\n",
    "\n",
    "winery_count = pd.DataFrame(df[\"winery\"].value_counts())\n",
    "winery_count[\"winery\"] = winery_count[\"winery\"]/len(winery_count[\"winery\"])\n",
    "df = pd.merge(df, winery_count, left_on=\"winery\", right_index=True)\n",
    "\n",
    "variety_count = pd.DataFrame(df[\"variety\"].value_counts())\n",
    "variety_count[\"variety\"] = variety_count[\"variety\"]/len(variety_count[\"variety\"])\n",
    "df = pd.merge(df, variety_count, left_on=\"variety\", right_index=True)\n",
    "\n",
    "\n",
    "designation_count = pd.DataFrame(df[\"designation\"].value_counts())\n",
    "designation_count[\"designation\"] = designation_count[\"designation\"]/len(designation_count[\"designation\"])\n",
    "df = pd.merge(df, designation_count, left_on=\"designation\", right_index=True)\n",
    "\n",
    "province_count = pd.DataFrame(df[\"province\"].value_counts())\n",
    "province_count[\"province\"] = province_count[\"province\"]/len(province_count[\"province\"])\n",
    "df = pd.merge(df, province_count, left_on=\"province\", right_index=True)\n",
    "\n",
    "country_count = pd.DataFrame(df[\"country\"].value_counts())\n",
    "country_count[\"country\"] = country_count[\"country\"]/len(country_count[\"country\"])\n",
    "df = pd.merge(df, country_count, left_on=\"country\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['points', 'price','winery_y', 'variety_y', 'designation_y', 'province_y',\n",
    "       'region_y', 'country_y']\n",
    "\n",
    "target = 'price'\n",
    "df1 = df[feature_list]\n",
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df1, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_test = test.drop(columns=target)\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_encoded = encoder.fit_transform(X_train) # 학습데이터\n",
    "X_train_encoded = scaler.fit_transform(X_train_encoded)\n",
    "X_val_encoded = encoder.transform(X_val) # 검증데이터\n",
    "X_val_encoded = scaler.fit_transform(X_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  15 | elapsed:   13.3s remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:   14.2s remaining:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  15 | elapsed:   15.9s remaining:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  1.0min remaining:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  4.8min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:  5.0min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  5.7min finished\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param = { \n",
    "    #50 ~ 100으로 실행했을 때 최적이 100옴\n",
    "    # 범위 변경 : (50~100) -> (50~500)\n",
    "    'n_estimators': randint(50, 500), \n",
    "    # 과적합을 방지하기 위해 max를 20으로 설정함 \n",
    "    'max_depth': [5, 10, 15, 20, None], \n",
    "    # 최대 선택할 특성 수\n",
    "    'max_features': uniform(0, 1), \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    RandomForestRegressor(random_state=42), \n",
    "    param_distributions=param, \n",
    "    n_iter=5, # 데이터의 훈련횟수\n",
    "    cv=3, # 교차검증 횟수\n",
    "    # mae은 에러 측정용으로써 낮을 수록 좋은데\n",
    "    # sklearn은 값이 클수록 좋다고 평가를 하기에 neg를 붙혀서 scoring으로 사용 \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    verbose=10, # 실행 과정 출력 여부\n",
    "    return_train_score=True, \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "search.fit(X_train_encoded, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼파라미터:  {'max_depth': None, 'max_features': 0.6011150117432088, 'n_estimators': 201}\n",
      "CV MAE:  11.818358042413374\n"
     ]
    }
   ],
   "source": [
    "print('최적 하이퍼파라미터: ', search.best_params_)\n",
    "print('CV MAE: ', -search.best_score_)\n",
    "model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 7 and input n_features is 825 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-18f41bbff908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"최적 모델 훈련 스코어 : {model.score(X_train_encoded, y_train)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"최적 모델 테스트 스코어 : {model.score(X_test, y_test)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 7 and input n_features is 825 "
     ]
    }
   ],
   "source": [
    "print(f\"최적 모델 훈련 스코어 : {model.score(X_train, y_train)}\")\n",
    "print(f\"최적 모델 테스트 스코어 : {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = X_test.iloc[[20]] \n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(row)\n",
    "\n",
    "shap.initjs()\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value, \n",
    "    shap_values=shap_values,\n",
    "    features=row\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.74221283820552"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"points\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
